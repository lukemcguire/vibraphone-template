---
phase: 04-configuration-output
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/crawler/worker.go
  - src/crawler/crawler.go
autonomous: true
requirements:
  - CRWL-05

must_haves:
  truths:
    - "User can limit crawl depth with --depth flag"
    - "Depth 0 means unlimited crawling"
    - "Depth 1 means start URL plus direct links only"
    - "Depth limit applies only to same-domain pages"
    - "External links are validated regardless of depth limit"
  artifacts:
    - path: "src/crawler/worker.go"
      provides: "Depth field in CrawlJob struct"
      contains: "Depth int"
    - path: "src/crawler/crawler.go"
      provides: "MaxDepth config and depth tracking in coordinator"
      contains: "MaxDepth"
  key_links:
    - from: "src/crawler/crawler.go"
      to: "CrawlJob.Depth"
      via: "depth increment when enqueueing discovered links"
      pattern: "Depth\\s*:"
---

<objective>
Add depth limiting capability to the crawler so users can restrict how deep the crawl traverses.

Purpose: Enable users to limit crawl scope for faster crawls or to stay within a specific depth from the start URL.
Output: Extended CrawlJob struct with Depth field, MaxDepth config option, and depth tracking in the BFS coordinator.
</objective>

<execution_context>
@/home/luke/.claude/get-shit-done/workflows/execute-plan.md
@/home/luke/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-configuration-output/04-CONTEXT.md
@.planning/phases/04-configuration-output/04-RESEARCH.md
@src/crawler/worker.go
@src/crawler/crawler.go
</context>

<tasks>

<task type="auto">
  <name>Add Depth field to CrawlJob struct</name>
  <files>src/crawler/worker.go</files>
  <action>
Add a `Depth int` field to the `CrawlJob` struct in worker.go.

The field should track the current depth of this job (0 = start URL, 1 = links from start URL, etc.).

Per user decision: depth is 0-indexed, so start URL is depth 0.

Update the `DefaultConfig` function to initialize the new `MaxDepth` field with 0 (unlimited).
  </action>
  <verify>
grep -q "Depth.*int" src/crawler/worker.go && echo "Depth field added"
  </verify>
  <done>
CrawlJob struct contains a Depth field of type int.
  </done>
</task>

<task type="auto">
  <name>Add MaxDepth to Config and implement depth tracking in coordinator</name>
  <files>src/crawler/crawler.go</files>
  <action>
1. Add `MaxDepth int` field to the `Config` struct. Per user decision: 0 = unlimited (default).

2. In the `Run` method's coordinator loop (around line 190-228), modify the link enqueueing logic:
   - Calculate `nextDepth := crawlResult.Job.Depth + 1` for discovered links
   - If `c.cfg.MaxDepth > 0 && nextDepth > c.cfg.MaxDepth`, skip enqueueing that link
   - Only apply depth limit to same-domain (internal) links; external links are always validated but never followed regardless

3. Update the initial job seeding (around line 147-148) to include `Depth: 0` for the start URL.

4. When creating new CrawlJob instances for discovered links, set `Depth: nextDepth`.

Per user decisions:
- Depth 0 = start URL
- Depth 1 = links from start URL (no further recursion)
- MaxDepth 0 = unlimited (crawl everything)
- Depth applies to same-domain only; external links are validated but never crawled
  </action>
  <verify>
grep -q "MaxDepth" src/crawler/crawler.go && grep -q "nextDepth" src/crawler/crawler.go && echo "Depth tracking implemented"
  </verify>
  <done>
Config has MaxDepth field, coordinator tracks and respects depth limits when enqueueing same-domain links.
  </done>
</task>

</tasks>

<verification>
- `go build ./...` compiles without errors
- `go test ./src/crawler/...` passes
- Depth tracking does not break existing crawl behavior (unlimited depth still works)
</verification>

<success_criteria>
- CrawlJob struct has Depth field
- Config struct has MaxDepth field
- Coordinator increments depth when enqueueing discovered same-domain links
- Coordinator skips enqueueing links that exceed MaxDepth (when MaxDepth > 0)
- External links are never followed regardless of depth
</success_criteria>

<output>
After completion, create `.planning/phases/04-configuration-output/04-01-SUMMARY.md`
</output>
