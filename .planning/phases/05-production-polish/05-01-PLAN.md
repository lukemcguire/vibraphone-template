---
phase: 05-production-polish
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/go.mod
  - src/crawler/visited.go
  - src/crawler/crawler.go
  - src/crawler/memory.go
autonomous: true
requirements: []
user_setup: []

must_haves:
  truths:
    - "Crawler tracks visited URLs without unbounded memory growth"
    - "Tool handles 100,000+ page crawls without OOM"
    - "Memory monitoring triggers throttling before system kills process"
  artifacts:
    - path: "src/crawler/visited.go"
      provides: "Disk-backed bloom filter for URL tracking"
      exports: ["VisitedTracker", "NewVisitedTracker"]
    - path: "src/crawler/memory.go"
      provides: "Memory pressure detection"
      exports: ["MemoryWatcher", "NewMemoryWatcher"]
  key_links:
    - from: "src/crawler/crawler.go"
      to: "src/crawler/visited.go"
      via: "Crawler.visited field"
      pattern: "VisitedTracker"
    - from: "src/crawler/memory.go"
      to: "runtime/debug"
      via: "SetMemoryLimit"
      pattern: "debug\\.SetMemoryLimit"
---

<objective>
Replace in-memory sync.Map URL tracking with disk-backed bloom filter and add memory pressure monitoring for production-scale crawls.

Purpose: Enable crawling 100,000+ pages without memory exhaustion while maintaining O(1) URL deduplication.
Output: Bounded-memory visited URL tracker and proactive memory monitoring.
</objective>

<execution_context>
@/home/luke/.claude/get-shit-done/workflows/execute-plan.md
@/home/luke/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-production-polish/05-CONTEXT.md
@.planning/phases/05-production-polish/05-RESEARCH.md
@src/crawler/crawler.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add bloom filter and mmap dependencies</name>
  <files>src/go.mod</files>
  <action>
Add the following dependencies to go.mod:
- `github.com/bits-and-blooms/bloom/v3` for bloom filter implementation
- `github.com/edsrzf/mmap-go` for memory-mapped file I/O

Run `go get github.com/bits-and-blooms/bloom/v3@latest` and `go get github.com/edsrzf/mmap-go@latest` from the src directory.

Per CONTEXT.md decision: Use disk-backed bloom filter with memory-mapped file for flat memory footprint at 100K+ page scale.
  </action>
  <verify>`go build ./...` succeeds and dependencies appear in go.mod</verify>
  <done>Dependencies added, go.mod updated, build succeeds</done>
</task>

<task type="auto">
  <name>Task 2: Create disk-backed bloom filter for URL tracking</name>
  <files>src/crawler/visited.go</files>
  <action>
Create a new file `src/crawler/visited.go` implementing a disk-backed bloom filter for URL tracking.

Implementation requirements from CONTEXT.md:
- Target scale: 100,000+ pages
- False positive rate: 0.1% (1 in 1000 chance of incorrectly skipping a URL)
- Memory-mapped file for constant memory footprint regardless of crawl size
- Thread-safe (wrap bloom filter operations with sync.Mutex)
- Periodic sync to disk (every 1000 URLs visited)
- Clean sync on Close()

Use the pattern from RESEARCH.md:
- `bloom.NewWithEstimates(100000, 0.001)` for filter sizing
- `mmap-go` for memory-mapped file backing
- Store in OS temp directory with cleanup on Close()

Exported API:
```go
type VisitedTracker struct { ... }
func NewVisitedTracker() (*VisitedTracker, error)  // Creates temp file in OS temp dir
func (v *VisitedTracker) Visit(url string)         // Mark URL as visited
func (v *VisitedTracker) IsVisited(url string) bool // Check if visited
func (v *VisitedTracker) VisitIfNew(url string) bool // Atomic test-and-set, returns true if new
func (v *VisitedTracker) Close() error             // Sync and cleanup
```

Do NOT hand-roll bloom filter math - use the library's NewWithEstimates which correctly computes optimal parameters.
  </action>
  <verify>`go build ./...` compiles, visited.go exports VisitedTracker type</verify>
  <done>VisitedTracker type with mmap-backed bloom filter implementation complete</done>
</task>

<task type="auto">
  <name>Task 3: Create memory pressure monitor</name>
  <files>src/crawler/memory.go</files>
  <action>
Create a new file `src/crawler/memory.go` implementing memory pressure monitoring.

Implementation requirements from CONTEXT.md:
- Use `runtime/debug.SetMemoryLimit()` to set soft memory limit (Go 1.19+)
- Use `runtime.ReadMemStats()` for monitoring current usage
- Trigger throttling when memory usage exceeds 75% of limit
- Target: 70-80% of available system memory (default to 1GB for CLI tool)

Exported API:
```go
type MemoryWatcher struct { ... }
type ThrottleLevel int // 0=normal, 1=warning, 2=critical

func NewMemoryWatcher(limitMB int64) *MemoryWatcher
func (m *MemoryWatcher) Check() (usedPercent float64, level ThrottleLevel)
func (m *MemoryWatcher) SetThrottleCallback(cb func(level ThrottleLevel))
```

Per RESEARCH.md pitfall #4: Set limit at 70-80% of available memory to avoid GC thrashing.
  </action>
  <verify>`go build ./...` compiles, memory.go exports MemoryWatcher type</verify>
  <done>MemoryWatcher with SetMemoryLimit integration complete</done>
</task>

<task type="auto">
  <name>Task 4: Integrate bloom filter into crawler</name>
  <files>src/crawler/crawler.go</files>
  <action>
Modify `src/crawler/crawler.go` to use VisitedTracker instead of sync.Map for visited URL tracking.

Changes:
1. Replace `visited sync.Map` field with `visited *VisitedTracker`
2. In `New()`: Initialize `visited` with `NewVisitedTracker()`
3. Replace all `c.visited.LoadOrStore()` calls with `c.visited.VisitIfNew()`
4. Replace all `c.visited.Store()` calls with `c.visited.Visit()`
5. Add `defer c.visited.Close()` at the start of `Run()` method

The bloom filter is NOT goroutine-safe per RESEARCH.md, so ensure all visited operations go through the mutex-protected VisitedTracker methods.

Do NOT change the crawling logic - only replace the visited URL tracking mechanism.
  </action>
  <verify>`go build ./...` and `go test ./src/crawler/...` pass</verify>
  <done>Crawler uses disk-backed bloom filter for URL tracking, tests pass</done>
</task>

</tasks>

<verification>
1. Run `go build ./...` - must compile without errors
2. Run `go test ./src/crawler/...` - all existing tests must pass
3. Verify visited.go exports VisitedTracker with all required methods
4. Verify memory.go exports MemoryWatcher with SetMemoryLimit integration
5. Verify crawler.go no longer uses sync.Map for visited tracking
</verification>

<success_criteria>
- VisitedTracker implements disk-backed bloom filter with 0.1% false positive rate
- MemoryWatcher integrates with runtime/debug.SetMemoryLimit
- Crawler uses VisitedTracker instead of sync.Map
- All existing tests pass
- Build succeeds
</success_criteria>

<output>
After completion, create `.planning/phases/05-production-polish/05-01-SUMMARY.md`
</output>
