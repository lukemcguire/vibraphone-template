---
phase: 05-production-polish
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/result/errors.go
  - src/crawler/worker.go
  - src/crawler/extract.go
autonomous: true
requirements: []
user_setup: []

must_haves:
  truths:
    - "Binary files (PDFs, images) are validated with HEAD request and skipped from parsing"
    - "Auth-gated pages (401/403) are classified as 'requires auth' not broken"
    - "Malformed HTML is treated as broken link and reported in results"
    - "Redirect chains have no hard limit, only cycle detection"
  artifacts:
    - path: "src/result/errors.go"
      provides: "Error classification including CategoryAuthRequired"
      exports: ["CategoryAuthRequired"]
    - path: "src/crawler/worker.go"
      provides: "Binary file detection and handling"
      pattern: "isBinaryContentType"
  key_links:
    - from: "src/crawler/worker.go"
      to: "src/result/errors.go"
      via: "ClassifyError"
      pattern: "CategoryAuthRequired"
    - from: "src/crawler/worker.go"
      to: "net/http"
      via: "HEAD request for binary files"
      pattern: "http\\.MethodHead"
---

<objective>
Handle edge cases gracefully for production use: binary files, auth-gated pages, and malformed HTML.

Purpose: Improve robustness when crawling real-world sites with mixed content types and access controls.
Output: Proper classification and handling of edge case responses.
</objective>

<execution_context>
@/home/luke/.claude/get-shit-done/workflows/execute-plan.md
@/home/luke/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-production-polish/05-CONTEXT.md
@.planning/phases/05-production-polish/05-RESEARCH.md
@src/crawler/worker.go
@src/result/errors.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add auth-required error category</name>
  <files>src/result/errors.go</files>
  <action>
Add a new error category for auth-gated pages.

Per CONTEXT.md decision: "Auth-gated pages (401/403) → detect and classify as 'requires auth' rather than broken"

Changes to `src/result/errors.go`:
1. Add constant: `CategoryAuthRequired ErrorCategory = "auth_required"`
2. Update `ClassifyError()` function to return `CategoryAuthRequired` for status codes 401 and 403
3. Update `FormatCategory()` to return "Requires Authentication" for `CategoryAuthRequired`

The 401/403 status codes should NOT be classified as Category4xx - they need special handling since they indicate the page exists but requires authentication, not that the link is broken.
  </action>
  <verify>`go build ./...` compiles, errors.go exports CategoryAuthRequired</verify>
  <done>CategoryAuthRequired added to error classification</done>
</task>

<task type="auto">
  <name>Task 2: Handle binary files with HEAD check</name>
  <files>src/crawler/worker.go</files>
  <action>
Modify `src/crawler/worker.go` to detect and handle binary files appropriately.

Per CONTEXT.md decision: "Binary files (PDFs, images, zips) → quick HEAD check, report as valid if 2xx response, skip parsing"

Implementation:
1. Create a helper function `isBinaryContentType(contentType string) bool` that checks for:
   - application/pdf
   - image/* (png, jpeg, gif, svg, webp, etc.)
   - application/zip, application/x-zip-compressed
   - application/octet-stream
   - video/*, audio/*

2. Modify internal link handling in `CheckURL()`:
   - After GET request, check `resp.Header.Get("Content-Type")`
   - If binary content type detected:
     - Status 2xx → return valid (no Links to extract)
     - Status >= 400 → classify as broken
   - Skip HTML parsing for binary files

3. For external binary links, the existing HEAD request logic already handles them correctly.

Do NOT download/store binary content - we only need to verify the link is valid.
  </action>
  <verify>`go build ./...` compiles, binary file URLs skip parsing</verify>
  <done>Binary files validated with status check, parsing skipped</done>
</task>

<task type="auto">
  <name>Task 3: Classify malformed HTML as broken</name>
  <files>src/crawler/extract.go, src/crawler/worker.go</files>
  <action>
Handle malformed HTML gracefully per CONTEXT.md decision: "Malformed HTML that fails to parse → treat as broken link, report in results"

Changes to `src/crawler/extract.go`:
- The current implementation already handles parse errors by collecting them and returning
- No changes needed - parse errors are already reported

Changes to `src/crawler/worker.go`:
- When `ExtractLinks()` returns an error for internal pages:
  - Create a LinkResult with error message "malformed HTML: parse error"
  - Set ErrorCategory to `CategoryUnknown` (or create new `CategoryMalformedHTML` if needed)
  - Include the parse error in the Error field
- The link should be marked as broken but not crash the crawler

The key insight: parse errors should create broken link results, not be silently ignored or crash the crawl.
  </action>
  <verify>`go build ./...` and `go test ./src/crawler/...` pass</verify>
  <done>Malformed HTML produces broken link result instead of crash</done>
</task>

</tasks>

<verification>
1. Run `go build ./...` - must compile without errors
2. Run `go test ./src/crawler/...` - all tests must pass
3. Verify CategoryAuthRequired is added to errors.go
4. Verify binary content detection works in worker.go
5. Verify malformed HTML creates broken link result
</verification>

<success_criteria>
- CategoryAuthRequired classifies 401/403 responses
- Binary files (PDFs, images, zips) are validated via status check without parsing
- Malformed HTML creates broken link results with appropriate error
- All existing tests pass
- Build succeeds
</success_criteria>

<output>
After completion, create `.planning/phases/05-production-polish/05-02-SUMMARY.md`
</output>
